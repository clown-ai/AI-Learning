{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phoneme Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIuM7V02aQOg9V285ZK9ge",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/358Xin/DL/blob/main/Phoneme_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cul4VQcKTMNB",
        "outputId": "34427399-0b5a-404a-c827-dfbbd5957f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR\n",
            "To: /content/data.zip\n",
            "100% 372M/372M [00:01<00:00, 234MB/s]\n",
            "Archive:  data.zip\n",
            "   creating: timit_11/\n",
            "  inflating: timit_11/train_11.npy   \n",
            "  inflating: timit_11/test_11.npy    \n",
            "  inflating: timit_11/train_label_11.npy  \n",
            "data.zip  sample_data  timit_11\n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR' --output data.zip\n",
        "!unzip data.zip\n",
        "!ls "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Loading data...\")\n",
        "data_root = './timit_11/'\n",
        "train_X = np.load(data_root + 'train_11.npy')\n",
        "train_Y = np.load(data_root + 'train_label_11.npy')\n",
        "test = np.load(data_root + 'test_11.npy')\n",
        "\n",
        "print(\"Size of training data: {}\".format(train_X.shape))\n",
        "print(\"Size of testing data: {}\".format(test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3qlVBkKUwaA",
        "outputId": "4d4f97f6-50d6-4aa7-87bb-6999007d7f70"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of testing data: (451552, 429)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TIMITDataset(Dataset):\n",
        "  def __init__(self, X, y=None):\n",
        "    self.data = torch.from_numpy(X).float()\n",
        "    if y is not None:\n",
        "      y = y.astype(np.int)\n",
        "      self.label = torch.LongTensor(y)\n",
        "    else:\n",
        "      self.label = None\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    if self.label is not None:\n",
        "      return self.data[index], self.label[index]\n",
        "    else:\n",
        "      return self.data[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "CEY6cinGVfnm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "划分训练集为训练集与验证集，因此此处给入一个valid_ratio"
      ],
      "metadata": {
        "id": "-dUWs8kbWjqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_ratio = 0.2\n",
        "percent = int(train_X.shape[0] * (1-valid_ratio))   #比重划分，之后进行分割\n",
        "train_x, train_y, valid_x, valid_y = train_X[:percent], train_Y[:percent], train_X[percent:], train_Y[percent:]\n",
        "print(\"Size of training set: {}\".format(train_x.shape))\n",
        "print(\"Size of validation set: {}\".format(valid_x.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nECB-6DXWdm1",
        "outputId": "59b39fed-2d44-4ad7-a29a-ce22e6696224"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: (983945, 429)\n",
            "Size of validation set: (245987, 429)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "有了Dataset之后创建DataLoader"
      ],
      "metadata": {
        "id": "5hOLtbaHYmGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = TIMITDataset(train_x, train_y)\n",
        "valid_set = TIMITDataset(valid_x, valid_y)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByToDZdKYiCX",
        "outputId": "cb4cd529-5281-41df-a3c8-4f344d082e3f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "做一下GC,此时的RAM与磁盘有点大了"
      ],
      "metadata": {
        "id": "drNqAy9VZpoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del train_X, train_Y, train_x, train_y, valid_x, valid_y\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArXQfC-4ZbIt",
        "outputId": "e859f5b0-51ce-4126-e53c-509a2a03b79b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2236"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "开始建立模型"
      ],
      "metadata": {
        "id": "oA2iFjxPZ_QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.layer1 = nn.Linear(429, 1024)\n",
        "    self.layer2 = nn.Linear(1024, 512)\n",
        "    self.layer3 = nn.Linear(512, 128)\n",
        "    self.out = nn.Linear(128, 39)\n",
        "    self.dropout = nn.Dropout(0.15)\n",
        "    self.activation = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.activation(x)\n",
        "\n",
        "    x = self.layer2(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.activation(x)\n",
        "\n",
        "    x = self.layer3(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.activation(x)\n",
        "\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "RWgN3eThaCP4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "开始训练"
      ],
      "metadata": {
        "id": "0Z6r6Q5VbWDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "iI06l0C3bUYi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def same_seeds(seed):\n",
        "  torch.backends.cudnn.deterministric = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "hC9kmm2IbiXG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "same_seeds(0)\n",
        "device = get_device()\n",
        "print(f\"Dvice: {device}\")\n",
        "num_epochs = 20\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.001\n",
        "model_path = './model.ckpt'\n",
        "\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tlTtA9NcxgQ",
        "outputId": "65a51926-1b50-43ab-f044-cd78976203dc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dvice: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_acc = 0.0\n",
        "  train_loss = 0.0\n",
        "  valid_acc = 0.0\n",
        "  valid_loss = 0.0\n",
        "\n",
        "  #train\n",
        "  model.train()\n",
        "  for inputs, labels in train_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)   #数据转device\n",
        "    optimizer.zero_grad()                     #从0梯度开始\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)             #计算损失\n",
        "    _, train_pred = torch.max(outputs, 1)           #以最大的概率得到类别的下标\n",
        "    loss.backward()                        #损失求导\n",
        "    optimizer.step()                       #更新\n",
        "\n",
        "    train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "    train_loss += loss.item()\n",
        "  \n",
        "  #validation\n",
        "  if len(valid_set) > 0:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in valid_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, valid_pred = torch.max(outputs, 1)\n",
        "\n",
        "        valid_acc += (valid_pred.cpu() == labels.cpu()).sum().item()\n",
        "        valid_loss += loss.item()\n",
        "      print('[{:2d}/{:2d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(epoch + 1, num_epochs, train_acc/len(train_set), train_loss/len(train_loader), valid_acc/len(valid_set), valid_loss/len(valid_loader)))\n",
        "\n",
        "      #考察模型表现是否有提升\n",
        "      if valid_acc > best_acc:\n",
        "        best_acc = valid_acc\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(\"Saving the model with acc {:.3f}\".format(best_acc/len(valid_set)))\n",
        "      else:\n",
        "        print('[{:2d}/{:2d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(epoch + 1, num_epochs, train_acc/len(train_set), train_loss/len(train_loader)))\n",
        "if len(valid_set) == 0:\n",
        "  torch.save(model.state_dict(), model_path)\n",
        "  print(\"Saving model at last epoch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk4gTQUCeHOZ",
        "outputId": "2c4574bd-cfbc-4cc6-c90e-688c32800dcd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1/20] Train Acc: 0.576637 Loss: 1.389694 | Val Acc: 0.658356 loss: 1.097302\n",
            "Saving the model with acc 0.658\n",
            "[ 2/20] Train Acc: 0.639295 Loss: 1.154364 | Val Acc: 0.682260 loss: 1.008956\n",
            "Saving the model with acc 0.682\n",
            "[ 3/20] Train Acc: 0.656807 Loss: 1.089702 | Val Acc: 0.687874 loss: 0.979401\n",
            "Saving the model with acc 0.688\n",
            "[ 4/20] Train Acc: 0.667187 Loss: 1.051945 | Val Acc: 0.695561 loss: 0.947114\n",
            "Saving the model with acc 0.696\n",
            "[ 5/20] Train Acc: 0.674732 Loss: 1.026505 | Val Acc: 0.700317 loss: 0.933694\n",
            "Saving the model with acc 0.700\n",
            "[ 6/20] Train Acc: 0.679900 Loss: 1.007311 | Val Acc: 0.702749 loss: 0.924192\n",
            "Saving the model with acc 0.703\n",
            "[ 7/20] Train Acc: 0.682953 Loss: 0.994167 | Val Acc: 0.707911 loss: 0.913820\n",
            "Saving the model with acc 0.708\n",
            "[ 8/20] Train Acc: 0.686179 Loss: 0.983410 | Val Acc: 0.707017 loss: 0.908492\n",
            "[ 8/20] Train Acc: 0.686179 Loss: 0.983410\n",
            "[ 9/20] Train Acc: 0.688892 Loss: 0.974500 | Val Acc: 0.710159 loss: 0.902964\n",
            "Saving the model with acc 0.710\n",
            "[10/20] Train Acc: 0.690926 Loss: 0.966977 | Val Acc: 0.710822 loss: 0.893585\n",
            "Saving the model with acc 0.711\n",
            "[11/20] Train Acc: 0.692375 Loss: 0.962258 | Val Acc: 0.711765 loss: 0.892679\n",
            "Saving the model with acc 0.712\n",
            "[12/20] Train Acc: 0.694352 Loss: 0.956626 | Val Acc: 0.713196 loss: 0.885977\n",
            "Saving the model with acc 0.713\n",
            "[13/20] Train Acc: 0.695226 Loss: 0.951579 | Val Acc: 0.713867 loss: 0.886672\n",
            "Saving the model with acc 0.714\n",
            "[14/20] Train Acc: 0.696297 Loss: 0.949173 | Val Acc: 0.716192 loss: 0.875896\n",
            "Saving the model with acc 0.716\n",
            "[15/20] Train Acc: 0.697107 Loss: 0.944341 | Val Acc: 0.713745 loss: 0.878790\n",
            "[15/20] Train Acc: 0.697107 Loss: 0.944341\n",
            "[16/20] Train Acc: 0.698251 Loss: 0.940649 | Val Acc: 0.714993 loss: 0.879724\n",
            "[16/20] Train Acc: 0.698251 Loss: 0.940649\n",
            "[17/20] Train Acc: 0.699319 Loss: 0.938467 | Val Acc: 0.714147 loss: 0.882445\n",
            "[17/20] Train Acc: 0.699319 Loss: 0.938467\n",
            "[18/20] Train Acc: 0.699529 Loss: 0.936618 | Val Acc: 0.719599 loss: 0.866206\n",
            "Saving the model with acc 0.720\n",
            "[19/20] Train Acc: 0.700675 Loss: 0.932712 | Val Acc: 0.717965 loss: 0.869740\n",
            "[19/20] Train Acc: 0.700675 Loss: 0.932712\n",
            "[20/20] Train Acc: 0.701466 Loss: 0.931410 | Val Acc: 0.717668 loss: 0.871665\n",
            "[20/20] Train Acc: 0.701466 Loss: 0.931410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试"
      ],
      "metadata": {
        "id": "ozA8YjVdseE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = TIMITDataset(test, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9BDe7KFscv-",
        "outputId": "bbbb2bb6-e71a-46a9-ab82-76e1e2898c5b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for inputs in test_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, test_pred = torch.max(outputs, 1)\n",
        "\n",
        "    for y in test_pred.cpu().numpy():\n",
        "      predict.append(y)\n",
        "with open('prediction.csv',\"w\") as f:\n",
        "  f.write(\"id, class\\n\")\n",
        "  for i, y in enumerate(predict):\n",
        "    f.write(\"{},{}\\n\".format(i, y))"
      ],
      "metadata": {
        "id": "I1XxScV2s0XO"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}