{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install qqdm","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:04.711026Z","iopub.execute_input":"2022-07-13T08:58:04.711781Z","iopub.status.idle":"2022-07-13T08:58:19.508659Z","shell.execute_reply.started":"2022-07-13T08:58:04.711690Z","shell.execute_reply":"2022-07-13T08:58:19.507592Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport glob\nfrom qqdm.notebook import  qqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch import optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:19.512595Z","iopub.execute_input":"2022-07-13T08:58:19.512885Z","iopub.status.idle":"2022-07-13T08:58:20.356419Z","shell.execute_reply.started":"2022-07-13T08:58:19.512858Z","shell.execute_reply":"2022-07-13T08:58:20.355454Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def same_seeds(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nsame_seeds(2021)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:20.357865Z","iopub.execute_input":"2022-07-13T08:58:20.358499Z","iopub.status.idle":"2022-07-13T08:58:20.430169Z","shell.execute_reply.started":"2022-07-13T08:58:20.358462Z","shell.execute_reply":"2022-07-13T08:58:20.429269Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CrypkoDataset(Dataset):\n    def __init__(self, fnames, transform):\n        self.tranform = transform\n        self.fnames = fnames\n        self.num_samples = len(self.fnames)\n    \n    def __getitem__(self, index):\n        fname = self.fnames[index]\n        img = torchvision.io.read_image(fname)\n        img = self.tranform(img)\n        return img\n    \n    def __len__(self):\n        return self.num_samples","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:20.433699Z","iopub.execute_input":"2022-07-13T08:58:20.434362Z","iopub.status.idle":"2022-07-13T08:58:20.440962Z","shell.execute_reply.started":"2022-07-13T08:58:20.434325Z","shell.execute_reply":"2022-07-13T08:58:20.440075Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_dataset(root):\n    fnames = glob.glob(os.path.join(root, \"*\"))\n    compose = [\n        transforms.ToPILImage(),\n        transforms.Resize((64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n    ]\n    transform = transforms.Compose(compose)\n    dataset = CrypkoDataset(fnames, transform)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:20.442197Z","iopub.execute_input":"2022-07-13T08:58:20.443007Z","iopub.status.idle":"2022-07-13T08:58:20.451022Z","shell.execute_reply.started":"2022-07-13T08:58:20.442970Z","shell.execute_reply":"2022-07-13T08:58:20.450099Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"workspace_dir = '../input/crypko-data/'\ndataset = get_dataset(os.path.join(workspace_dir, \"faces\"))\nimages = [dataset[i] for i in range(16)]\ngrid_img = torchvision.utils.make_grid(images, nrow=4)\nplt.figure(figsize=(10, 10))\nplt.imshow(grid_img.permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:20.452452Z","iopub.execute_input":"2022-07-13T08:58:20.453063Z","iopub.status.idle":"2022-07-13T08:58:21.726842Z","shell.execute_reply.started":"2022-07-13T08:58:20.453014Z","shell.execute_reply":"2022-07-13T08:58:21.726014Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"images = [(dataset[i]+1)/2 for i in range(16)]\ngrid_img = torchvision.utils.make_grid(images, nrow=4)\nplt.figure(figsize=(10, 10))\nplt.imshow(grid_img.permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:21.727949Z","iopub.execute_input":"2022-07-13T08:58:21.728442Z","iopub.status.idle":"2022-07-13T08:58:22.163728Z","shell.execute_reply.started":"2022-07-13T08:58:21.728405Z","shell.execute_reply":"2022-07-13T08:58:22.162707Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:22.167137Z","iopub.execute_input":"2022-07-13T08:58:22.167797Z","iopub.status.idle":"2022-07-13T08:58:22.174116Z","shell.execute_reply.started":"2022-07-13T08:58:22.167761Z","shell.execute_reply":"2022-07-13T08:58:22.173095Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, in_dim, dim=64):\n        super(Generator, self).__init__()\n        def dconv_bn_relu(in_dim, out_dim):\n            return nn.Sequential(\n              nn.ConvTranspose2d(in_dim, out_dim, 5, 2, padding=2, output_padding=1, bias=False),\n              nn.BatchNorm2d(out_dim),\n              nn.ReLU()\n            )\n    \n        self.l1 = nn.Sequential(\n              nn.Linear(in_dim, dim*8*4*4, bias=False),\n              nn.BatchNorm1d(dim*8*4*4),\n              nn.ReLU()\n        )\n\n        self.l2_5 = nn.Sequential(\n              dconv_bn_relu(dim*8, dim*4),\n              dconv_bn_relu(dim*4, dim*2),\n              dconv_bn_relu(dim*2, dim),\n              nn.ConvTranspose2d(dim, 3, 5, 2, padding=2, output_padding=1),\n              nn.Tanh()\n        )\n\n        self.apply(weights_init)\n    def forward(self, x):\n        y = self.l1(x)\n        y = y.view(y.size(0), -1, 4, 4)\n        y = self.l2_5(y)\n        return y","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:22.175457Z","iopub.execute_input":"2022-07-13T08:58:22.176471Z","iopub.status.idle":"2022-07-13T08:58:22.190376Z","shell.execute_reply.started":"2022-07-13T08:58:22.176435Z","shell.execute_reply":"2022-07-13T08:58:22.189351Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, in_dim, dim=64):\n        super(Discriminator, self).__init__()\n        def conv_bn_lrelu(in_dim, out_dim):\n            return nn.Sequential(\n              nn.Conv2d(in_dim, out_dim, 5, 2, 2),\n              nn.BatchNorm2d(out_dim),\n              nn.ReLU()\n            )\n    \n        self.ls = nn.Sequential(\n              nn.Conv2d(in_dim, dim, 5, 2, 2),\n              nn.LeakyReLU(0.2),\n              conv_bn_lrelu(dim, dim*2),\n              conv_bn_lrelu(dim*2, dim*4),\n              conv_bn_lrelu(dim*4, dim*8),\n              nn.Conv2d(dim*8, 1, 4),\n              nn.Sigmoid()\n        )\n\n        self.apply(weights_init)\n    \n    def forward(self, x):\n        y = self.ls(x)\n        y = y.view(-1)\n        return y","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:58:22.194703Z","iopub.execute_input":"2022-07-13T08:58:22.194989Z","iopub.status.idle":"2022-07-13T08:58:22.204253Z","shell.execute_reply.started":"2022-07-13T08:58:22.194965Z","shell.execute_reply":"2022-07-13T08:58:22.203104Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nz_dim = 100\nz_sample = Variable(torch.randn(100, z_dim)).cuda()\nlr = 1e-4\n\nn_epochs = 50\nn_critic = 5\nclip_value = 0.01\n\noutput_path = \"./\"\nlog_dir = os.path.join(output_path, 'logs')\nckpt_dir = os.path.join(output_path, 'checkpoints')\nos.makedirs(log_dir, exist_ok=True)\nos.makedirs(ckpt_dir, exist_ok=True)\n\nG = Generator(in_dim=z_dim).cuda()\nD = Discriminator(3).cuda()\nG.train()\nD.train()\n\ncriterion = nn.BCELoss()\n\nopt_D = optim.RMSprop(D.parameters(), lr=lr)\nopt_G = optim.RMSprop(G.parameters(), lr=lr)\n\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T08:59:12.195330Z","iopub.execute_input":"2022-07-13T08:59:12.195777Z","iopub.status.idle":"2022-07-13T08:59:15.424652Z","shell.execute_reply.started":"2022-07-13T08:59:12.195735Z","shell.execute_reply":"2022-07-13T08:59:15.423664Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch.autograd as autograd\n\ndef Gradient_Penalty(D, real_data, fake_data):\n    alpha = torch.rand((real_data.size(0), 1, 1, 1)).cuda()\n    \n    interpolates = alpha*real_data + (1-alpha)*fake_data\n    interpolates = autograd.Variable(interpolates, requires_grad=True)\n    d_interpolates = D(interpolates)\n    \n    gradient_penalty = autograd.grad(\n        outputs = d_interpolates,\n        inputs = interpolates,\n        grad_outputs = torch.ones(d_interpolates.size()).cuda(),\n        create_graph = True,\n        retain_graph = True,\n        only_inputs = True\n    )[0]\n    gp = gradient_penalty[0].view(gradient_penalty[0].size()[0], -1)\n    gradient_penalty = ((gp.norm(2, dim=1)-1)**2).mean()\n    return gradient_penalty","metadata":{"execution":{"iopub.status.busy":"2022-07-13T09:01:25.829940Z","iopub.execute_input":"2022-07-13T09:01:25.830625Z","iopub.status.idle":"2022-07-13T09:01:25.838572Z","shell.execute_reply.started":"2022-07-13T09:01:25.830587Z","shell.execute_reply":"2022-07-13T09:01:25.837409Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"steps = 0\nfor e, epoch in enumerate(range(n_epochs)):\n    progress_bar = qqdm(dataloader)\n    for i, data in enumerate(progress_bar):\n        imgs = data\n        imgs = imgs.cuda()\n        bs = imgs.size(0)\n\n        z = Variable(torch.randn(bs, z_dim)).cuda()\n        r_imgs = Variable(imgs).cuda()\n        f_imgs = G(z)\n\n        r_label = torch.ones((bs)).cuda()\n        f_label = torch.zeros((bs)).cuda()\n\n        r_logit = D(r_imgs.detach())\n        f_logit = D(f_imgs.detach())\n\n        r_loss = criterion(r_logit, r_label)\n        f_loss = criterion(f_logit, f_label)\n        \n        gradient_penalty = Gradient_Penalty(D, r_imgs.data, f_imgs.data)\n        loss_D = -torch.mean(D(r_imgs)) + torch.mean(D(f_imgs)) + 0.1 * gradient_penalty\n\n        D.zero_grad()\n        loss_D.backward()\n        opt_D.step()\n    \n        for p in D.parameters():\n            p.data.clamp_(-clip_value, clip_value)\n\n        if steps % n_critic == 0:\n            z = Variable(torch.randn(bs, z_dim)).cuda()\n            f_imgs = G(z)\n            f_logit = D(f_imgs)\n            loss_G = -torch.mean(D(f_imgs))\n            G.zero_grad()\n            loss_G.backward()\n            opt_G.step()\n        steps += 1\n\n        progress_bar.set_infos({\n            'Loss_D':round(loss_D.item(), 4),\n            'Loss_G':round(loss_G.item(), 4),\n            'Epoch':e+1,\n            'Step':steps\n        })\n    G.eval()\n    f_imgs_sample = (G(z_sample).data + 1) / 2.0\n    filename = os.path.join(log_dir, f\"Epoch_{epoch+1:03d}.jpg\")\n    torchvision.utils.save_image(f_imgs_sample, filename, nrow=10)\n    print(f\" | Save some samples to {filename}.\")\n\n    grid_img = torchvision.utils.make_grid(f_imgs_sample.cpu(), nrow=10)\n    plt.figure(figsize=(10,10))\n    plt.imshow(grid_img.permute(1,2,0))\n    plt.show()\n    G.train()\n\n    if(e+1)%5==0 or e==0:\n        torch.save(G.state_dict(), os.path.join(ckpt_dir, 'G.pth'))\n        torch.save(D.state_dict(), os.path.join(ckpt_dir, 'D.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T09:01:29.022183Z","iopub.execute_input":"2022-07-13T09:01:29.022644Z","iopub.status.idle":"2022-07-13T13:39:56.561426Z","shell.execute_reply.started":"2022-07-13T09:01:29.022608Z","shell.execute_reply":"2022-07-13T13:39:56.560334Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n\ndef file2zip(packgePath, zipPath):\n    Zip = zipfile.ZipFile(zipPath, 'w', zipfile.ZIP_DEFLATED)\n    for path, firNames, fileNames in os.walk(packgePath):\n        fpath = path.replace(packgePath, '')\n        for name in fileNames:\n            fullName = os.path.join(path,  name)\n            name = fpath + '\\\\' + name\n            Zip.write(fullName, name)\n    Zip.close()\n\nif __name__ == \"__main__\":\n    packagePath = '/kaggle/working/logs'\n    zipPath = '/kaggle/working/output.zip'\n    if os.path.exists(zipPath):\n        os.remove(zipPath)\n    file2zip(packagePath, zipPath)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-13T14:07:02.177695Z","iopub.execute_input":"2022-07-13T14:07:02.178171Z","iopub.status.idle":"2022-07-13T14:07:02.513635Z","shell.execute_reply.started":"2022-07-13T14:07:02.178131Z","shell.execute_reply":"2022-07-13T14:07:02.511112Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}